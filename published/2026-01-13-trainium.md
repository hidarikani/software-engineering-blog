Have you heard about a new chemical element called Trainium? It comes after Uranium â€” just kidding ğŸ˜.

Trainium is AWSâ€™s in-house machine learning accelerator. At the recent re:Invent keynote, the AWS CEO made it clear that the company plans to expand its use of custom silicon, including Graviton CPUs, rather than remain indefinitely dependent on NVIDIA.

NVIDIAâ€™s flagship GPUs are likely still ahead in raw performance, but AWS is optimizing for priceâ€“performance at massive scale. By designing its own chips and tightly integrating them with its infrastructure, AWS can offer lower training costs per model and more predictable economics for large, long-running workloads â€” even if peak performance is lower.

Itâ€™s also useful to be precise with terminology. NVIDIAâ€™s data-center products are GPUs: originally graphics processors that evolved into highly programmable, general-purpose compute devices via CUDA. They can support a wide range of workloads â€” training, inference, simulation, and rendering â€” and adapt as AI architectures evolve.

Trainium, by contrast, is an ASIC: a domain-specific accelerator built specifically for machine learning training. ASICs trade flexibility for efficiency and perform best when the workload closely matches their design assumptions. In AWSâ€™s lineup, Trainium targets training workloads, while Inferentia is optimized for inference.

