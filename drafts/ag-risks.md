# Is AGI going to starve humanity to death?

Over the end-of-year Christmas and New Year holidays, I listened to multiple podcasts discussing the risk assessment of creating artificial general intelligence. I have summarized the main arguments and concerns in the text below.

## Supply chain monopoly

TSMC, located on the island of Taiwan, is currently the only foundry known to produce frontier chips capable of fueling the AI revolution. Internally, TSMC depends on another company, ASML, based in the Netherlands, which specializes in producing extreme ultraviolet (EUV) lithography machines. In turn, ASML depends on Zeiss, a German company that specializes in the lenses used to focus EUV light.

In reverse order, Zeiss supplies ASML, which supplies TSMC, which then supplies Nvidia, AMD, and Intel. These companies, in turn, supply OpenAI and other AGI-focused startups. This creates a highly centralized and fragile supply chain for advanced AI development.

## Generalization of business and intelligence

Businesses tend to generalize over time. A good example of this process is Amazon. Amazon started as an online bookstore, but to grow its business it gradually expanded into selling almost every type of product. Later, the company realized that the internal computing platform it had built could be sold externally, which led to the creation of its cloud business. Cloud computing is essentially the sale of generalized compute.

Similarly, OpenAI and other AGI startups are transitioning toward selling generalized intelligence in the form of foundation models and AI agents. Selling generalized intelligence appears to be the ultimate business goal—the holy grail of capitalism.

## Humanoid robots

While companies like OpenAI focus on the frontier of cognitive AGI, other companies such as Tesla are working toward humanoid robots that could replace manual labor in factories, construction, and even household chores. AI doomers argue that, based on current trends, cognitive office jobs performed on computers will be automated first, followed later by manual labor jobs once robotics matures.

## Race condition

Corporations dream of outperforming every other business on the planet. For a long time, this idea belonged to science fiction, but it is starting to look plausible if a company gains control over AGI. Such a system could compete across medicine, finance, law, programming—essentially any domain.

This creates extreme anxiety around being first. Whoever develops AGI first is perceived as having the potential to rule the world. It increasingly resembles a form of economic worship: those who worship money are attempting to build an artificial god, hoping they can control it and extract infinite wealth.

## Political deregulation

The current stance of political superpowers, particularly the United States, appears to be one of deregulation in the AI field. By deregulation, I mean a refusal to establish meaningful constraints. As a result, massive amounts of venture capital are being poured into AI data centers, alongside plans to build new nuclear power plants or acquire existing ones solely to power these facilities.

These data centers are being built because large corporations are betting that they will unlock AGI. The political incentive is clear: whichever country reaches AGI first may gain unprecedented abundance for its citizens and an immense competitive advantage over other nations.

This logic often aligns with nationalist thinking—the belief that one’s own country is morally superior to others, for example the U.S. viewing itself as superior to China or Russia. Following this reasoning, global domination becomes morally justifiable in the name of “winning” the AI race.

## Worshipping a false god

AI doomers argue that people working in AGI-focused startups are driven half by fear and half by fascination with the artificial god they are trying to create. The fear is that by working on AGI, they might secure their own relevance, longevity, or survival in a future where most humans become obsolete.

Ironically, by building tools that automate AI research itself, these workers may accelerate their own obsolescence. The fascination comes from pride—the belief that the greatest achievement of a lifetime would be creating something superior to oneself, something that inherits the creator’s values and traits. For example, if Western society “wins” the AGI race, there is hope that AGI would prioritize Western cultural values.

## Whistleblowers

Some AI experts have become whistleblowers, publicly challenging the moral and ethical implications of building AGI. They are skeptical of ideas such as universal basic income. If all cognitive jobs—and eventually manual labor via humanoid robots—are controlled by one or a few corporations, there is little incentive for those corporations to share power or wealth.

This could create a world where much of the population effectively becomes disposable or enslaved. Citizens of the dominant country might experience slightly better conditions, but global wealth-sharing would be even less likely. Such a scenario risks unprecedented social instability, as societies lose both purpose and the means to earn a living. Mass unemployment on this scale could lead to riots, systemic collapse, and widespread starvation.
